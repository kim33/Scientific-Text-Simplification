--
-- PostgreSQL database dump
--

-- Dumped from database version 16.9 (Ubuntu 16.9-0ubuntu0.24.04.1)
-- Dumped by pg_dump version 16.9 (Ubuntu 16.9-0ubuntu0.24.04.1)

SET statement_timeout = 0;
SET lock_timeout = 0;
SET idle_in_transaction_session_timeout = 0;
SET client_encoding = 'UTF8';
SET standard_conforming_strings = on;
SELECT pg_catalog.set_config('search_path', '', false);
SET check_function_bodies = false;
SET xmloption = content;
SET client_min_messages = warning;
SET row_security = off;

SET default_tablespace = '';

SET default_table_access_method = heap;

--
-- Name: responses; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.responses (
    user_id integer NOT NULL,
    passage_id integer,
    understanding text,
    naturalness text,
    simplicity text,
    understanding_comment text,
    naturalness_comment text,
    simplicity_comment text,
    id integer NOT NULL,
    complex_a text,
    complex_b text
);


ALTER TABLE public.responses OWNER TO postgres;

--
-- Name: responses_id_seq; Type: SEQUENCE; Schema: public; Owner: postgres
--

CREATE SEQUENCE public.responses_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER SEQUENCE public.responses_id_seq OWNER TO postgres;

--
-- Name: responses_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: postgres
--

ALTER SEQUENCE public.responses_id_seq OWNED BY public.responses.id;


--
-- Name: responses id; Type: DEFAULT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.responses ALTER COLUMN id SET DEFAULT nextval('public.responses_id_seq'::regclass);


--
-- Data for Name: responses; Type: TABLE DATA; Schema: public; Owner: postgres
--

COPY public.responses (user_id, passage_id, understanding, naturalness, simplicity, understanding_comment, naturalness_comment, simplicity_comment, id, complex_a, complex_b) FROM stdin;
351	501	Passage 2	Passage 2	Passage 2	Much less special lingo in 2	Same reasoning as above	Shorter sentences, easily understandable	105	A TAG-Based Noisy-Channel Model Of Speech Repairs This paper describes a noisy channel model of speech repairs, which can identify and correct repairs in speech transcripts.:::\n A [syntactic parser] is used as the [source model], and a novel type of [TAG-based transducer] is the [channel model].:::\n The use of TAG is motivated by the intuition that the [reparandum] is a "rough copy" of the repair.:::\n The model is trained and tested on the [Switchboard disfluency-annotated corpus].:::\n [Noisy channel models] do well on the [disfluency detection task].:::\n Although the standard noisy channel model performs well, a [log linear re-ranker] can be used to increase performance.:::\n Our TAG system achieves a high [EDIT-F score], largely as a result of its explicit tracking of overlapping words between [reparanda and alterations].	N/A
354	511	Passage 2	Passage 2	No Difference	better grammar and use of synonyms makes it easier to read	Passage 1 reads like a collection of sentences, Passage 2 like a text	Passage 1 has shorter sentences, Passage 2 ist better understandable	106	Discovering Relations Among Named Entities From Large Corpora Discovering the significant relations embedded in documents would be very useful not only for information retrieval but also for question answering and summarization.	Discovering Relations Among Named Entities From [Large Corpora Discovering] the significant relations embedded in documents would be very useful not only for information retrieval but also for question answering and summarization
354	512	Passage 1	No Difference	No Difference	the added clarifications in brackets	the differ mostly in a few synonyms	the differ mostly in a few synonyms	107	N/A	We examine the utility of different features such as Wordnet hypernyms, parts of speech, and entity types, and find that the dependency tree kernel achieves a 20% F1 improvement over a [bag-of-words kernel]. 
354	513	Passage 2	Passage 2	No Difference	simpler word choices	Passage 1 is overloaded with scientific terms	the passages differ mostly in word choice	108	We present AImed, a corpus for the evaluation of [PPI] extraction systems	N/A
358	521	Passage 2	Passage 2	Passage 2	Passage 2 uses simpler words.	N/A	Passage 1 has more conjuctions while Passage 2 has shorter simple sentances.	109	By doing so, the common predictive structure shared by the multiple classification problems can be discovered, which can then be used to improve performance on the target problem.	N/A
358	522	Passage 1	Passage 2	Passage 2	Passage 1 explains the technical words better.	No excess explaination.	Sentances are very simple.	110	In experiments using the Penn WSJ corpus, our automatically trained model gave a performance of [86.6% (F1, sentences <= 40 words)], which is comparable to that of an unlexicalized [PCFG parse]r created using extensive manual feature selection.	N/A
360	531	Passage 2	Passage 2	Passage 2	The words are easier, especially for non native speakers and those not used to talking about computer learning usw. Passage 2 also seems to explain things better, even though it  conveys the same information.	Closer to spoken language.	While the sentences are about the same lenght, the ones in Passage 2 feel more fluent and connected through the usage of conjunctions.	111	The model is formally a [synchronous] context-free grammar but is learned from a bitext without any syntactic information.:::\n We note that whenever we combine two dynamic programming items, we need to score the [fluency of their concatentation] by incorporating the score of any language model features which cross the [target side boundaries of the two concatenated items].:::\n We use the [k-best parsing algorithm in a CFG-based log-linear translation model] in order to learn feature weights which maximize BLEU.	The model is technically a [synchronous] context-free grammar, but it is learned from a pair of aligned texts (bitext) without using any grammar rules.:::\n We use the [k-best parsing method] in a grammar-based model to find the best feature weights that improve BLEU scores.
360	532	Passage 1	Passage 1	Passage 1	easier words	sentences are structured less complex	sentences are linked better	112	N/A	This method requires a source language dependency [parser], target language word segmentation and an unsupervised word alignment component.:::\n We align a [parallel corpus], project the [source dependency parse] onto the target sentence, extract dependency treelet translation pairs, and train a tree-based ordering model.:::\n We describe an efficient decoder and show that using these tree-based models in combination with [conventional SMT models] provides a promising approach that incorporates the power of phrasal SMT with the linguistic [generality] available in a [parser].
364	541	Passage 2	Passage 2	Passage 2	Explains context for readers without a technical background	Passage 2 uses more everyday phrasing (an essential part of being good at a language)vs. Passage 1's academic expressions (a fundamental component of language competency.)	Passage 2 breaks down sentences and makes the content more digestible	114	We develop a SVM categoriser combining a classifier based on trigram language models (one for each level of difficulty), some parsing features such as average tree height, and variables traditionally used in readability.:::\n Reading Level Assessment Using Support Vector Machines And Statistical Language Models Reading proficiency is a fundamental component of language competency.	n/a
364	542	Passage 1	Passage 1	Passage 1	phrases like “break down the sentence” and “rearranging the words" in Passage 1 are clearer than technical phrases like “parse the source language string” or “surface string" from Passage 2	Passage 1 is less formal	Passage 1 breaks ideas into short, direct sentences. Passage 2 describes complex ideas with longer, technical sentences	115	Clause Restructuring For Statistical Machine Translation We describe a method for incorporating syntactic information in statistical machine translation systems.:::\n The first step of the method is to parse the source language string that is being translated.:::\n The second step is to apply a series of transformations to the parse tree, effectively reordering the surface string on the source language side of the translation system.:::\n The reordering approach is applied as a pre-processing step in both the training and decoding phases of a phrase-based statistical MT system.	We point out it's unsure if the conditions needed for another method, called bootstrap resampling, apply to Bleu scores, so we suggest using the sign test.
364	548	Passage 1	Passage 1	Passage 2	explaining definitions	more approachable	less clear but passage 2 looks cleaner without parenthesis/added context	124	Randomized Algorithms And NLP: Using Locality Sensitive Hash Functions For High Speed Noun Clustering In this paper, we explore the power of randomized algorithm to address the challenge of working with very large amounts of data.	We reduce the running time from quadratic (which grows quickly as data increases) to practically linear (grows slowly with more data) in the number of elements to be computed.:::\n We show that by using the LSH (Locality Sensitive Hashing, a method to find similar items) nearest neighbors calculation can be done in O(nd) time (a way to describe how fast an algorithm runs).
364	543	Passage 2	Passage 2	Passage 2	Passage 2 explains unfamiliar technical terms 	Passage 2 uses clearer everyday language	Passage 1 feels packed with long and formal technical sentences	116	In this paper, we present a syntax-based statistical machine translation system based on a probabilistic synchronous dependency insertion grammar.:::\n Synchronous dependency insertion grammars are a version of synchronous grammars defined on dependency trees.:::\n We first introduce our approach to inducing such a grammar from parallel corpora.:::\n Second, we describe the graphical model for the machine translation task, which can also be viewed as a stochastic tree-to-tree transducer.:::\n We introduce a polynomial time decoding algorithm for the model.:::\n We present a translation model based on Synchronous Dependency Insertion Grammar (SDIG), which handles some of the non-isomorphism but requires both source and target dependency structures.	Next, we describe our method for translation using a visual model that acts like a tree-to-tree converter, changing one language structure into another using probability.:::\n In this paper, we introduce a system that uses these statistical methods with a specific type of grammar called probabilistic synchronous dependency insertion grammar.
364	544	Passage 1	Passage 1	Passage 1	Simpler words	More direct	Too many jargons in Passage 2	117	n/a	Arabic Tokenization Part-Of-Speech Tagging And Morphological Disambiguation In One Fell Swoop We present an approach to using a morphological analyzer for tokenizing and morphologically tagging (including part-of-speech tagging) Arabic words in one process.:::\n We learn classifiers for individual morphological features, as well as ways of using these classifiers to choose among entries from the output of the analyzer.
10	31	Passage 2	No Difference	Passage 1	test test test test a	test test test test a	test test test test a	118	A Comparison Of Alignment Models For Statistical Machine Translation In this paper, we present and compare various alignnment models for statistical machine translation.	To improve word sequence models in the Hidden Markov Model (HMM) based matching, we make these models depend on word categories.
11	31	Passage 1	No Difference	Passage 2	testestestesttestestestesttestestestest	testestestesttestestestesttestestestest	testestestesttestestestesttestestestest	119	In order to improve transition models in the HMM based alignment, we extend the transition models to be word-class dependent.	We also look at how different matching methods affect the quality of translations in a statistical machine translation system.
364	545	Passage 2	Passage 2	Passage 2	explains definition of unfamiliar terms	less academic	passage 1 sentences are dense and nested	120	Semantic Role Labeling Using Different Syntactic Views Semantic role labeling is the process of annotating the predicate-argument structure in text with semantic labels.:::\n In this paper we present a state-of-the-art baseline semantic role labeling system based on Support Vector Machine classifiers.:::\n In order to address this problem, we combined semantic parses from a Minipar syntactic parse and from a chunked syntactic representation with our original baseline system which was based on Charniak parses.:::\n We use the Constituent, Predicate, and Predicate-Constituent related features for the kernel, resulting in the best performance.:::\n We combine the outputs of multiple parsers to extract reliable syntactic information, which is translated into features for a machine learning experiment in assigning semantic roles.	To fix this, we combined different sentence structure analyses from Minipar and a simplified method with our original system based on Charniak's analysis.
364	546	Passage 1	Passage 1	Passage 1	easier words, definition provided. (it's still a bit long though)	more conversational	sentences too complex in passage 2	121	Joint Learning Improves Semantic Role Labeling Despite much recent progress on accurate semantic role labeling, previous work has largely used independent classifiers, possibly combined with separate label sequence models via Viterbi decoding.:::\n This stands in stark contrast to the linguistic observation that a core argument frame is a joint structure, with strong dependencies between arguments.:::\n We show how to build a joint model of argument frames, incorporating novel features that model these interactions into discriminative log-linear models.:::\n This system achieves an error reduction of 22% on all arguments and 32% on core arguments over a state-of-the art independent classifier for gold-standard parse trees on PropBank.:::\n We introduce a joint approach for SRL and demonstrate that a model that scores the full predicate argument structure of a parse tree could lead to significant error reduction over independent classifiers for each predicate-argument relation.:::\n We employ decomposition for efficiency in training: that is, the decomposition allows us to train the classification models on a subset of training examples consisting only of those phrases that have a case marker.	Joint Learning Improves Semantic Role Labeling Despite much recent progress in accurately identifying and labeling the roles words play in sentences (semantic role labeling), previous methods mostly used separate tools that worked independently, sometimes combining these with other models that sequence labels using a method called Viterbi decoding.
364	547	Passage 2	Passage 2	Passage 2	easier words	more natural	more direct sentences but still long	122	We define a paraphrase probability that allows paraphrases extracted from a bilingual parallel corpus to be ranked using translation probabilities, and show how it can be refined to take contextual information into account.:::\n We evaluate our paraphrase extraction and ranking methods using a set of manual word alignments, and contrast the quality with paraphrases extracted from automatic alignments.:::\n We define a paraphrasing probability between two phrases based on their translation probability through all possible pivot phrases.:::\n Paraphrasing With Bilingual Parallel Corpora Previous work has used monolingual parallel corpora to extract and generate paraphrases.	Paraphrasing With Bilingual Parallel Corpora Previous work has used collections of similar texts in the same language to find and create paraphrases, which are different ways of saying the same thing.:::\n We define a way to measure how likely something is a paraphrase, which helps organize paraphrases found in two-language text collections using how likely they are to translate, and show how to improve this by considering surrounding words.:::\n By using methods from computer programs that translate languages, we show how you can find paraphrases in one language by using a phrase in another language as a middle step.
12	31	Passage 1	Passage 2	Passage 2	testestsetestsesetestes	testestsetestsesetestes	testestsetestsesetestes	123	A Comparison Of Alignment Models For Statistical Machine Translation In this paper, we present and compare various alignnment models for statistical machine translation.	To improve word sequence models in the Hidden Markov Model (HMM) based matching, we make these models depend on word categories.
364	549	Passage 2	Passage 2	Passage 2	easier words	more natural expressions	some words didn't necessarily need added explainers in passage 2, but still easier to read	125	This paper demonstrates that match with respect to domain and time is also important, and presents preliminary experiments with training data labeled with emoticons, which has the potential of being independent of domain, topic and time.:::\n Traditional machine learning techniques have been applied to this problem with reasonable success, but they have been shown to work well only when there is a good match between the training and test data with respect to topic.	n/a
13	41	Passage 2	Passage 1	No Difference	testestestestsetetsete	testestestestsetetsete	testestestestsetetsete	126	Efficient Parsing Of Highly Ambiguous Context-Free Grammars With Bit Vectors An efficient bit-vector-based CKY-style parser for context-free parsing is presented.	We use the Viterbi algorithm, which is good at handling situations with many possible grammar interpretations.
13	42	Passage 2	Passage 2	No Difference	We suggest a way to combine the supertagger with the parser: at first, only a few categories are given to each word, and more are added if the parser can't find a complete analysis.	We suggest a way to combine the supertagger with the parser: at first, only a few categories are given to each word, and more are added if the parser can't find a complete analysis.	We suggest a way to combine the supertagger with the parser: at first, only a few categories are given to each word, and more are added if the parser can't find a complete analysis.	127	We suggest a way to combine the supertagger with the parser: at first, only a few categories are given to each word, and more are added if the parser can't find a complete analysis.	The Importance Of Supertagging For Wide-Coverage CCG Parsing This paper explains the role of supertagging, which is like a label assigning process, in a CCG parser that uses a mathematical method to choose the best analysis.:::\n We suggest a way to combine the supertagger with the parser: at first, only a few categories are given to each word, and more are added if the parser can't find a complete analysis.
13	43	Passage 2	Passage 1	No Difference	We suggest a way to combine the supertagger with the parser: at first, only a few categories are given to each word, and more are added if the parser can't find a complete analysis.	We suggest a way to combine the supertagger with the parser: at first, only a few categories are given to each word, and more are added if the parser can't find a complete analysis.	We suggest a way to combine the supertagger with the parser: at first, only a few categories are given to each word, and more are added if the parser can't find a complete analysis.	128	We introduce a sentence level QE system where an arbitrary threshold is used to classify the MT output as good or bad.	Various methods for determining whether MT (Machine Translation) output is correct are investigated, for both whole sentences and words.
14	41	Passage 2	Passage 2	No Difference	We suggest a way to combine the supertagger with the parser: at first, only a few categories are given to each word, and more are added if the parser can't find a complete analysis.	We suggest a way to combine the supertagger with the parser: at first, only a few categories are given to each word, and more are added if the parser can't find a complete analysis.	We suggest a way to combine the supertagger with the parser: at first, only a few categories are given to each word, and more are added if the parser can't find a complete analysis.	129	Efficient Parsing Of Highly Ambiguous Context-Free Grammars With Bit Vectors An efficient bit-vector-based CKY-style parser for context-free parsing is presented.	This parser is especially useful when every possible analysis is needed, not just the most likely one.
364	550	Passage 1	Passage 1	Passage 1	easier words	more natural expressions	less technical	130	n/a	Multi-Engine Machine Translation Guided By Explicit Word Matching We describe a new approach for synthetically combining the output of several different Machine Translation (MT) engines operating on the same input.:::\n The goal is to produce a synthetic combination that surpasses all of the original systems in translation quality.:::\n Our approach uses the individual MT engines as "black boxes" and does not require any explicit cooperation from the original MT systems.:::\n A decoding algorithm uses explicit word matches, in conjunction with confidence estimates for the various engines and a trigram language model in order to score and rank a collection of sentence hypotheses that are synthetic combinations of words from the various original engines.
365	551	Passage 2	No Difference	Passage 2	passage 2 uses easier language	Both passages are grammatically correct	simple sentence structures	131	We create a [corpus] of course lectures segmented by four annotators, noting that the annotators operated at different levels of [granularity].:::\n Our results demonstrate that global analysis improves the [segmentation accuracy] and is robust in the presence of speech recognition errors.	We focus on finding the best way to cut based on how similar the sentences are to each other, using a method similar to [cosine similarity] (a way to measure how alike two things are).
365	552	Passage 1	Passage 2	Passage 1	Simple sentence structure	Sentences are longer but make sense more.	Simple sentence structure	132	N/A	Highly [coreferent paths] also allow mining of precise probabilistic gender/number information.:::\n Given an automatically parsed corpus, we extract from each parse tree a dependency path, which is represented as a sequence of nodes and dependency labels connecting a pronoun and a candidate [antecedent], and collect statistical information from these paths to determine the likelihood that a pronoun and a candidate antecedent connected by a given path are coreferent.:::\n We build a statistical model from paths that include [the lemma of the intermediate tokens], but replace the end nodes with noun, pronoun, or pronoun-self for nouns, pronouns, and reflexive pronouns, respectively.
365	553	Passage 2	No Difference	Passage 2	Easier vocabs	Both sound natural in English	simple sentence structure	133	Moreover, the CRF has efficient training and decoding processes which both find globally [optimal] solutions.:::\n We show how a large number of highly predictive features can be easily incorporated into the CRF, and [demonstrate] that even with only a few hundred word-aligned training sentences, our model improves over the current [state-of-the-art] with [alignment] error rates of 5.29 and 25.8 for the two tasks respectively.	N/A
365	554	Passage 1	No Difference	Passage 1	easier terms	Both speaks good english	simpler sentence structure	134	We introduce two different methods for changing names: one uses sound-based [transliteration] and the other looks at how often the name pairs appear together over time.	We present two [distinct] methods for transliteration, one approach using [phonetic transliteration], and the second using the temporal distribution of candidate pairs.:::\n We then propose [a novel score propagation method] that utilizes the co-occurrence of transliteration pairs within document pairs.:::\n This [propagation] method achieves further improvement over the best results from the previous step.
365	555	Passage 2	No Difference	Passage 2	less technical terms are used	Both passages sound natural in english	passage 2 sounds simpler	135	This method enables us to extract useful machine translation training data even from very [non-parallel corpora], which contain no parallel sentence pairs.:::\n We first use the GI ZA++ [(with grow-diag-final-and heuristic)] to obtain the word alignment between source and target words, and then calculate the association strength between the aligned words.:::\n We first extract the candidate parallel sentences from the comparable corpora and further extract the accurate [sub-sentential] bilingual fragments from the candidate parallel sentences using the in-domain probabilistic [bilingual lexicon.]:::\n We perform phrase extraction by combining clean [alignment lexica] for initial signals with heuristics to smooth alignments for final fragment extraction.	N/A
366	551	Passage 2	Passage 2	Passage 1	states the goal explicitly 	less repetitive, no notable grammatical errors when Passage 1 has one (a normalized minimum-cut criteria-> "a normalized minimum-cut criterion" OR "normalized minimum-cut criteria")	shorter sentences	136	Our results demonstrate that global analysis improves the segmentation accuracy and is robust in the presence of [speech recognition errors].	Our method looks at the big picture instead of just small parts and considers how well everything sticks together over long stretches.:::\n We focus on finding the best way to cut based on how similar the sentences are to each other, using a method similar to cosine similarity (a way to measure how alike two things are).:::\n Our findings show that this broader view helps us cut the lecture more accurately, even when there are mistakes in the speech-to-text process.
15	41	Passage 2	Passage 2	Passage 2	Passage 2 is easier to grasp because it replaces dense terms (“novel deep-learning architecture”) with simpler ones (“new deep-learning model”), breaks long sentences into shorter, clearer statements, and avoids parenthetical clauses such as “while also outlining,” so the paper’s objective emerges with less ambiguity.	Passage 2 sounds more natural.\nIts sentences are shorter and more direct, it uses everyday verbs such as “present” and “combines” instead of heavier phrases like “introduce a novel architecture,” and it avoids stacked modifiers (e.g., “robust performance in handling noisy data”) that make Passage 1 feel denser. Both passages are grammatically correct, but Passage 2’s simpler word choices and cleaner sentence structure give it a smoother, more fluent flow.	Passage 2 again comes out ahead.\nEvery sentence is short enough to fit on one-to-two text lines, avoids subordinate clauses (“although,” “while,” “whereas”), and sticks to a clear subject-verb-object pattern, so a reader can skim a single sentence and immediately grasp a key point (e.g., “Tests on standard datasets show that this model improves accuracy by 15%…”). Passage 1, by contrast, strings together multiple ideas in longer sentences that often spill beyond two rows, making it harder to spot the main content at a glance.	137	Recent advancements in [machine learning] have led to significant improvements in [natural language processing (NLP)].\nIn this study, researchers introduce a novel [deep learning architecture] that integrates [convolutional neural networks] with [recurrent neural networks] to enhance text understanding.\nExperimental results on [benchmark datasets] show that the proposed model achieves a 15 % improvement in accuracy over traditional methods.\nAdditionally, the model demonstrates robust performance in handling [noisy data] and [long-range dependencies] within text.\nThe authors discuss potential applications in [sentiment analysis], [machine translation], and [information extraction], while also outlining future work to further optimize the model’s efficiency and scalability.	In this study, researchers present a new [deep learning model] that combines [convolutional and recurrent neural networks] to better understand text.\n\nThe authors highlight potential uses in [sentiment analysis], [machine translation], and [information extraction], and they plan to continue improving the model’s efficiency and scalability.
15	42	Passage 1	Passage 2	Passage 1	Passage 1 is easier to grasp.\nIt replaces technical terms such as “log-linear model,” “derivation space,” and “normal-form derivation model” with everyday phrases like “mathematical method” and “label-assigning process,” breaks ideas into shorter, plainly worded sentences, and relies on clear cause-and-effect statements (“The supertagger makes the process more efficient by reducing the number of possible options…”). Passage 2, by contrast, packs dense jargon and longer noun phrases into single sentences, so the paper’s objective is harder to spot without prior knowledge of parsing theory.	Passage 2 sounds more natural.\nIts sentences follow standard academic‐English patterns (“reduces the derivation space over which model estimation is performed”), keep subjects and verbs close together, and avoid informal or awkward phrases such as “label assigning process,” “grammar created by a machine,” or “you can achieve much faster speeds,” which make Passage 1 feel less polished. Despite the heavier jargon, Passage 2’s syntax, word choice, and punctuation read smoothly and contain no grammatical slips, giving it a more fluent, professional tone.\n\n\n\n\n\n\n\n\n\n	Passage 1.\nMost of its points are broken into shorter, plain-language sentences without stacked clauses, so readers can process each idea quickly. Passage 2 often compresses multiple technical phrases into longer sentences, making its structure comparatively more complex.	138	This paper explains the role of [supertagging] in a [CCG parser] that uses a [mathematical method] to choose the best analysis.\n\nThe [supertagger] makes the process more efficient by reducing the number of possible options the model needs to evaluate, which also makes training faster.\n\nCCG parsing has two steps: first, the [supertagger] assigns likely [categories] to each word, and then a few rules—along with [type-changing] and [punctuation rules]—help build a [structured representation] using a method called the [CKY algorithm].\n\nWe suggest a way to combine the [supertagger] with the [parser]: at first, only a few categories are given to each word, and more are added if the parser can’t find a complete analysis.	This paper describes the role of [supertagging] in a [wide-coverage CCG parser] which uses a [log-linear model] to select an analysis.\n\nWe show that large increases in speed can be obtained by tightly integrating the [supertagger] with the [CCG grammar] and parser.\n\nThis is the first work we are aware of to successfully integrate a [supertagger] with a [full parser] which uses an [automatically extracted grammar].\n\nThe result is an accurate [wide-coverage CCG parser] which is an [order of magnitude] faster than comparable systems for other [linguistically motivated formalisms].\n\nThe [CCG parsing] consists of two phases: first the [supertagger] assigns the most probable [categories] to each word, and then the small number of [combinatory rules], plus the [type-changing] and [punctuation rules], are used with the [CKY algorithm] to build a [packed chart].\n\nWe propose a method for integrating the [supertagger] with the parser: initially a small number of [categories] is assigned to each word, and more categories are requested if the parser can not find a [spanning analysis].
15	43	Passage 2	Passage 1	Passage 1	Passage 2 is easier to follow.\nIt replaces less common terms like “notion” and “arbitrary threshold” with plainer phrases such as “idea” and “chosen limit,” and it explicitly spells out abbreviations—adding “(Machine Translation)” after “MT” and “(Quality Estimation)” after “QE.” Those small tweaks reduce jargon and ambiguity, so the paper’s objective—evaluating ways to judge MT quality at sentence and word levels—comes across more clearly.\n\n\n\n\n\n\n\n\n\n	Passage 1 sounds a little more natural overall.\nIts word choices (“arbitrary threshold,” “notion of correctness,” “sentence-level QE system”) match standard academic English and read smoothly, whereas some substitutions in Passage 2—such as “idea of correctness is not easy to understand” and “chosen limit”—feel slightly informal or awkward. Both passages are grammatically correct, but Passage 1’s vocabulary and phrasing align better with conventional, fluent scholarly style.\n\n\n\n\n\n\n\n\n\n	Passage 1—its sentences are a little shorter and have fewer parenthetical insertions or stacked phrases, so each idea is delivered in a cleaner, more easily digestible structure.	139	Various methods for determining whether [MT] output is correct are investigated, for both [whole sentences] and [words].\n\nSince the [notion of correctness] is not intuitively clear in this context, different ways of defining it are proposed.\n\nWe introduce a [sentence-level QE system] where an [arbitrary threshold] is used to classify the [MT output] as good or bad.	Since the [idea of correctness] is not easy to understand in this context, different ways of defining it are proposed.\nWe introduce a [sentence-level QE (Quality Estimation) system] where a chosen limit is used to classify the [MT output] as good or bad.
365	560	Passage 1	No Difference	Passage 1	better explanation for technical terms	both sound natural in English	shorter and simpler sentence structure	151	N/A	Much of this improvement, however, is based upon an [ever-increasing] number of features to be trained on (typically) the WSJ treebank data.:::\n This paper should allay these fears.:::\n We successfully applied self-training to parsing by [exploiting] available unlabeled data, and obtained remarkable results when the same technique was applied to parser adaptation.
15	44	Passage 1	Passage 2	Passage 1	Passage 1 is easier to grasp.\nIt replaces dense technical phrases (“monolingual sentence-level paraphrases from a corpus of temporally and topically clustered news articles”) with plainer language (“sentences with the same meaning but different words from news articles grouped by time and topic”), breaks long ideas into shorter statements, and offers quick glosses for jargon (e.g., explaining edit distance as “counting changes needed to make them the same”). Those choices reduce ambiguity and let the paper’s objective—building a large paraphrase corpus using two unsupervised methods—stand out clearly.	Passage 2 reads more naturally in standard academic English.\nIts sentences follow familiar scholarly patterns (“We investigate unsupervised techniques for acquiring monolingual sentence-level paraphrases …”), avoid contractions such as “don’t,” maintain consistent terminology, and keep subjects and verbs close together, giving the prose a smooth, formal flow. Passage 1, by contrast, mixes conversational wording (“look into methods that don’t need human guidance,” “rule of thumb”) with some awkward constructions (“a scoring method from translating languages”), which makes it feel less polished even though both passages are largely grammatical.\n\n\n\n\n\n\n\n\n\n	Passage 1 uses simpler sentence structure.\nMost ideas are broken into shorter, standalone sentences with basic subject-verb-object patterns and few embedded clauses, making each point easy to process quickly. Passage 2, although well-written, frequently packs multiple technical phrases into longer sentences and uses more subordinate clauses (e.g., “collected from thousands of web-based news sources”), which increases structural complexity.	140	We look into methods that don't need human guidance for finding [paraphrases] from a [collection of news articles] grouped by time and topic from many online news sources.\n\nWe use two methods: (1) [simple string edit distance], and (2) a [heuristic strategy] that pairs initial sentences from different news stories in the same group.\n\nResults show that the [edit-distance data] is cleaner and easier to match, with an [alignment error rate (AER)] of 11.58 % on a similar test set.\n\nWe introduce the [Microsoft Research Paraphrase Corpus (MSRPC)], which leverages [web-aggregated news stories] to learn both sentence- and word-level alignments.	We investigate [unsupervised techniques] for acquiring [monolingual sentence-level paraphrases] from a corpus of [temporally and topically clustered news articles] collected from thousands of [web-based news sources].\n\nTwo techniques are employed: (1) [simple string edit distance], and (2) a [heuristic strategy] that pairs initial (presumably summary) sentences from different news stories in the same cluster.\n\nResults show that edit-distance data is cleaner and more easily aligned than the heuristic data, with an overall [alignment error rate (AER)] of 11.58 % on a similarly extracted test set.\n\nOn test data extracted by the [heuristic strategy], however, performance of the two training sets is similar, with [AERs] of 13.2 % and 14.7 % respectively.\n\nAnalysis of 100 pairs of sentences from each set reveals that the edit-distance data lacks many of the complex [lexical and syntactic alternations] that characterize [monolingual paraphrase].\n\nThe summary sentences, while less readily alignable, retain more of the [non-trivial alternations] that are of greatest interest when learning [paraphrase relationships].
15	45	Passage 2	Passage 1	Passage 2	Passage 2 is easier to grasp.\nIt swaps specialized terms like “unsupervised language-model adaptation techniques” and “interpolated with a general background model” for plainer phrases (“adjust language models … without human guidance,” “combined with a general model”), breaks dense ideas into shorter sentences, and repeats the core workflow in straightforward language (“turn results into search requests,” “find similar sentences,” “create specific language models”). Those choices eliminate jargon and reduce sentence complexity, so the paper’s main objective—using MT output as queries to build better language models that improve translation—emerges with the least ambiguity.\n\n\n\n\n\n\n\n\n\n	Passage 1 reads more naturally in polished academic English.\nIts sentences employ standard technical terms (“unsupervised language-model adaptation,” “interpolated with a general background model”) and vary rhythm without awkward repetition. Passage 2, while perfectly grammatical, relies on informal or slightly clumsy substitutes (“search requests,” “big improvements,” “adjust language models … without human guidance”) and repeats the same ideas almost verbatim in successive sentences, which makes the prose feel less smooth and professional.\n\n\n\n\n\n\n\n\n\n	Passage 2.\nIts points are divided into shorter, straightforward sentences with few embedded clauses, making each step of the method easy to follow, whereas Passage 1 often compresses several technical details into longer, multi-clause statements.	141	The hypotheses from the [machine translation output] are converted into [queries at different levels of representation power] and used to extract similar sentences from a [very large monolingual text collection].\n\nWe apply a slightly different [sentence-level strategy] to language-model adaptation, first generating an [nbest list] with a [baseline system], then finding similar sentences in a [monolingual target-language corpus].\n\nWe construct [specific language models] by using [machine translation output] as queries to extract similar sentences from [large monolingual corpora].	The results from the translation process are turned into [search requests] at [different levels of detail] and used to find similar sentences from a [huge collection of text] in one language.\n\nWe use a slightly different method by first creating a list of possible translations, then finding similar sentences in a [text collection] of the [target language].\n\nWe make specific language models by using [machine translation results] as [search requests] to find similar sentences in [large text collections].\n\nWe change initial [machine translation guesses] into [search requests] and find similar sentences from a [large collection of text] in one language.
15	46	Passage 1	Passage 2	Passage 1	Passage 1 is easier to grasp.\nIt swaps technical phrases like “corpus level,” “product‐moment,” and “higher-ordered n-grams” for ordinary words (“large set of texts,” “two-word matches”), breaks ideas into brisk, declarative sentences, and consistently explains jargon in plain language (“accuracy and smoothness,” “human opinions can be unreliable and costly”). That straightforward wording and sentence structure make the paper’s aim—offering ORANGE as a way to test MT-evaluation metrics without extra human effort—immediately clear and unambiguous.	Passage 2 sounds more natural and polished.\nIts sentences follow standard academic phrasing (“are usually conducted on corpus level,” “we introduce a new evaluation method”), it uses precise connectors (“however,” “such comparisons rely on”), and it avoids conversational fillers like “looking at things like” found in Passage 1. The terminology is consistent and domain-appropriate, and punctuation is handled cleanly, giving the prose a smoother, more professional flow with no noticeable grammatical slips.\n\n\n\n\n\n\n\n\n\n	Passage 1.\nMost of its ideas are delivered in short, stand-alone sentences with basic subject-verb-object patterns and few embedded clauses, so the structure is quick to parse. Passage 2 often stacks multiple technical phrases in one sentence (e.g., the long opening sentence describing correlation statistics), which makes its syntax denser and harder to scan at a glance.	142	Comparisons of [automatic evaluation measures] for [machine translation] are usually done on a large set of texts using [statistical methods] like [Pearson’s correlation coefficient] or [Spearman’s rank correlation coefficient].\n\nHowever, these comparisons depend on [human opinions] about how good the translation is, looking at things like [how accurate and smooth] it is.\n\nIn this paper, we introduce a new method called [ORANGE], which allows us to evaluate [automatic translation evaluation tools] without needing [extra human input], except for using a set of [reference translations].\n\nBLEU, a common evaluation tool, is adjusted (Lin and Och, 2004b) and it only looks at [two-word matches] because this aligns better with [human opinions] than using [longer word sequences].\n\n\n\n\n\n\n\n\n\n	Comparisons of [automatic evaluation metrics] for [machine translation] are usually conducted on [corpus level] using [correlation statistics] such as [Pearson’s product-moment correlation coefficient] or [Spearman’s rank-order correlation coefficient] between [human scores] and [automatic scores].\n\nIn this paper, we introduce a new evaluation method, [ORANGE], for evaluating [automatic machine-translation evaluation metrics] automatically without [extra human involvement] other than using a set of [reference translations].\n\n[BLEU] is [smoothed] (Lin and Och, 2004b), and it considers only matching up to [bigrams] because this has higher correlations with [human judgments] than when [higher-ordered n-grams] are included.\n\n\n\n\n\n\n\n\n\n
15	47	Passage 2	Passage 1	Passage 2	Passage 2 is easier to understand.\nIt substitutes technical terms like “clump-based,” “linguistic phrases,” and “broad-coverage rule-based parsers” with everyday wording (“group-based,” “language phrases,” “tools that analyze sentence structure”), explains jargon in parentheses (e.g., defining parsers and the BLEU metric), and breaks dense ideas into shorter, direct sentences—so the paper’s aim of learning rewrite patterns to fix word-order problems in machine translation is immediately clear and unambiguous.\n\n\n\n\n\n\n\n\n\n	Passage 1 reads more naturally in polished academic English.\nIts terminology (“clump-based statistical MT systems,” “broad-coverage rule-based parsers”) and sentence rhythm match the conventions of research writing, it avoids contractions, and it stays concise without parenthetical asides that break flow. Passage 2, though grammatical, introduces informal touches (“don’t,” “tools that analyze sentence structure”), repeats ideas almost verbatim, and uses slightly awkward substitutions (“group-based,” “while running”), so the prose feels less smooth and professional.	Passage 2.\nIts ideas are broken into shorter, plain sentences—often one clause each—and it adds clarifying parentheses instead of embedding long, technical phrases inside single statements, so readers can process each point quickly. Passage 1 bundles more information into longer, multi-clause sentences and uses denser technical wording, making its structure comparatively more complex.	143	Current [clump-based statistical MT systems] have two limitations with respect to word ordering: first, they lack a [mechanism for expressing and using generalization] that accounts for reorderings of [linguistic phrases].\n\nTo address these limitations, we propose to use [automatically learned rewrite patterns] to preprocess the source sentences so that they have a word order similar to that of the [target language].\n\nThe basic model is statistical, but we use [broad-coverage rule-based parsers] in two ways—during [training] for learning rewrite patterns and at [runtime] for reordering the source sentences.\n\nOur [reordering rules] are automatically learned from aligning [parse trees] for both the source and target sentences.	Current [group-based statistical machine translation (MT) systems] have two problems with word order: first, they don’t have a way to handle changes in word order that cover different language phrases.\n\nTo fix these problems, we suggest using [automatically learned rewrite patterns] to rearrange the words in the original sentences so they match the order of the target language.\n\nThe main model is statistical, but we also use [rule-based parsers] in two ways—one during [training] to learn rewrite patterns and the other while [running] to rearrange the original sentences.
365	556	Passage 1	No Difference	Passage 1	easier terms, less technical vocabs	both sounds natural in english	shorter sentences with explanations	144	N/A	In this paper, we present a method for reducing the granularity of the WordNet sense inventory based on the mapping to a manually crafted dictionary encoding sense [hierarchies], namely the Oxford Dictionary of English.:::\n In our [coarse-grained task], the sense inventory was first clustered semi-automatically with each cluster representing an equivalence class over senses.
25	83	Passage 2	No Difference	Passage 2	extra explanation	both sound natural	simpler sentences	212	A subset of the [acquisition algorithm] is implemented and the results are used to [attgment] and critique the structure of [a large hand-built thesaurus.]:::\n We identify a set of [lexico-syntactic patterns] that are easily recognizable, that occur frequently and across text genre boundaries, and that indisputably indicate the lexical relation of interest.	n/a
15	48	Passage 1	Passage 2	Passage 1	Passage 1 is easier to grasp.\nIt replaces dense academic phrases such as “lexicon,” “bi-tag HMMs,” and “non-training intensive framework” with plainer words like “dictionary,” “simpler method,” and “doesn’t require extensive training,” and it briefly defines technical ideas (e.g., “a tool that labels words in a sentence”). Sentences are shorter, connectors are straightforward, and there are fewer embedded clauses, so the paper’s main objective—building and evaluating a context-aware HMM tagger whose accuracy hinges on dictionary quality—emerges clearly and without ambiguity.\n\n\n\n\n\n\n\n\n\n	Passage 2 sounds more natural and polished.\nIts sentences follow standard academic style (“we present,” “evaluate it in both the unsupervised and supervised case”), employ precise vocabulary (“lexicon,” “state-of-the-art,” “framework”), and avoid informal wording or minor slips such as “with help (supervised)” found in Passage 1. Passage 2 also keeps grammatical structures consistent and uses smoother connectors (“Finally,” “Observing that”), giving the prose a fluent, professional flow without awkward pauses or redundancies.	Passage 1.\nIts ideas are mostly delivered in short, single-clause sentences (often under 20 words) with straightforward subject-verb-object patterns and minimal parenthetical insertions, so each point can be digested quickly. Passage 2, by contrast, often packs several technical phrases into longer, multi-clause sentences—especially in the opening and closing lines—which makes its structure denser and slightly harder to scan at a glance.	145	We also provide the first detailed comparison of [unsupervised methods] for labeling [parts of speech], pointing out that previous results have not been consistent across different sets of texts or dictionaries.\n\nWe find that the dictionary's quality greatly affects how accurate the labeling is, so we offer a way to train [HMMs] that makes the labeling more accurate when the dictionary is unstable.\n\nWhile repeating previous tests, we find that success relies on cleaning up the [tag dictionaries] with helpful data from the text.\n\nWe show that the [expectation maximization algorithm], a method for improving accuracy in tagging, works well with [HMMs] when we have a dictionary and certain favorable conditions.\n\nWe notice that past high results in [unsupervised HMM-EM] tests were due to using improved dictionaries, where only common word analyses were included.\n\n\n\n\n\n\n\n\n\n	We present a new [HMM tagger] that exploits context on both sides of a word to be tagged, and evaluate it in both the [unsupervised] and [supervised] case.\n\nAlong the way, we present the first comprehensive comparison of [unsupervised methods] for [part-of-speech tagging], noting that published results to date have not been comparable across [corpora] or [lexicons].\n\nObserving that the quality of the [lexicon] greatly impacts the accuracy that can be achieved by the algorithms, we present a method of [HMM training] that improves accuracy when training of [lexical probabilities] is unstable.\n\nWhile replicating earlier experiments, we discover that performance was highly dependent on cleaning [tag dictionaries] using statistics gleaned from the tokens.\n\nWe show that the [expectation maximization algorithm] for [bi-tag HMMs] is efficient and quite effective for acquiring accurate POS taggers given only a [lexicon] ([tag dictionary]) and certain favorable conditions.\n\nWe observe that earlier [unsupervised HMM-EM] results were artificially high due to use of [Optimized Lexicons], in which only frequent-enough analyses of each word were kept.
15	49	Passage 2	Passage 2	Passage 2	Passage 2 is easier to follow.\nIt replaces technical jargon like “linear-chain conditional random fields (CRFs) to perform robust and accurate Chinese word segmentation by providing a principled framework” with plain, explanatory phrases (“a method called linear-chain conditional random fields … can effectively handle Chinese word segmentation”), defines the task in everyday terms (“breaking down sentences into words”), and explains CRFs as “a statistical tool for analyzing sequences.” Sentences are shorter, definitions are embedded where needed, and the workflow—segmenting characters and detecting new words—is described in simple yes-or-no decisions, so the paper’s objective comes across with minimal ambiguity.	Passage 2 sounds more natural overall.\nIts sentences flow smoothly, avoid duplication, and contain no obvious grammatical slips, whereas Passage 1 repeats ideas almost verbatim, contains awkward phrasing (“was also demonstrated in word segmentation)”), and has mismatched punctuation. Passage 2 keeps terminology consistent, explains concepts clearly, and maintains a steady, readable rhythm, giving it the more fluent, polished feel.	Passage 2.\nMost ideas are delivered in short, single-clause sentences (e.g., “We also introduce a method for finding new words, which helps improve accuracy.”), and technical concepts are broken into step-by-step descriptions—so readers can grasp each point quickly. Passage 1, by contrast, packs multiple technical phrases into longer, multi-clause sentences and repeats similar statements, making its structure denser and harder to scan at a glance.	146	This paper demonstrates the ability of [linear-chain conditional random fields (CRFs)] to perform robust and accurate Chinese word segmentation by providing a [principled framework] that easily supports the integration of domain knowledge via [multiple lexicons of characters and words].\n\nCRF is a [statistical sequence-modeling framework] introduced by [Lafferty et al. (2001)], and we use it for the Chinese word-segmentation task by treating word segmentation as a [binary decision task].\n\nWe first use this framework for Chinese word segmentation by treating it as a [binary decision task], such that each character is labeled either as the [beginning of a word] or the [continuation of one].\n\nWe define the [word-segmentation problem] as labeling each character according to whether the [previous character boundary] of the current character is a [word boundary].\n\n\n\n\n\n\n\n\n\n	This paper shows how a method called [linear-chain conditional random fields (CRFs)] can effectively handle Chinese word segmentation by providing a [structured approach] that easily incorporates [specialized knowledge] using [various lists of characters and words].\n\nCRF is a [statistical tool for analyzing sequences], introduced by Lafferty et al. (2001), and we use it for Chinese word segmentation by [treating it as a task] where you make [yes-or-no decisions].\n\nWe apply this method by [labeling each character as either the start of a new word or a continuation of the current word].\n\nWe define the word-segmentation problem by [deciding if each character is the start of a new word or continues from the previous character].
365	557	Passage 1	No Difference	Passage 1	easier terms and shorter sentences	both sounds natural in English	shorter sentences	147	We present an empirical comparison of Espresso with various state of the art systems, on different size and [genre corpora], on extracting various general and specific relations.:::\n Experimental results show that our [exploitation] of generic patterns substantially increases system recall with small effect on overall [precision.]:::\n In the pattern [induction step], our system computes a [reliability score] for each candidate pattern based on the weighted pointwise mutual information, PMI, of the pattern with all instances extracted so far.	Our program, which doesn't need much [supervision], starts with a single set that mixes different types of examples, like leader-panel and oxygen-water, which relate to member-of and part-of relationships as described by Keet and Artale in 2008.
15	50	Passage 1	Passage 2	Passage 1	Passage 1 is easier to understand.\nIt translates the technical workflow into everyday language—e.g., “identifying the main parts of sentences and the meaning behind them” rather than “identifying predicate-argument structures,” and “make informed guesses” instead of “perform structured probabilistic inference.” Jargon such as “semantic representations,” “domain and scenario model,” or “scalable and expressive representation” is either simplified or omitted. Sentences are generally shorter, with clear step-by-step explanations, so the paper’s goal—using semantic structures plus probabilistic reasoning to answer tough natural-language questions—emerges with little ambiguity.\n\n\n\n\n\n\n\n\n\n	Passage 2 reads more naturally in polished academic English.\nIts sentences follow standard scholarly phrasing (“complex questions posed in Natural Language,” “performing structured probabilistic inference”), use precise connectors (“In this paper we describe…,” “The results indicate…”), and avoid colloquial expressions like “make informed guesses” that appear in Passage 1. Terminology is used consistently, clauses are balanced, and punctuation is smooth, giving Passage 2 a fluent, professional cadence with no noticeable grammatical slips.	Passage 1.\nMost ideas are broken into shorter, single-clause sentences with everyday wording (“make informed guesses,” “using the relationships we extract”) and only occasional parenthetical phrases, so each step is quick to parse. Passage 2 often combines several technical phrases in longer, multi-clause sentences—especially when describing semantic representations and inference—making its structure denser and harder to scan at a glance.	148	The ability to answer hard questions written in everyday language depends on (1) how detailed the [semantic information] is and (2) the [reasoning methods] that this information supports.\n\nIn this paper, we describe a [question-answering (QA) system] where questions are examined and possible answers are generated by 1) identifying the [main parts of sentences] and the [meaning] behind them from the input, and 2) using these [extracted relationships] to make [informed guesses] within a [specific topic or situation].\n\nA new feature of our system is a flexible and clear way of showing actions and events using [Coordinated Probabilistic Relational Models (CPRM)], which is a method to predict outcomes based on relationships.\n\nOur [QA system] uses [PropBank/FrameNet labels] as input, which help identify what actions are being described and with what details, and then it gives an answer by using [models that predict actions based on chance and reasoning].	The ability to answer complex questions posed in [Natural Language] depends on (1) the depth of the available [semantic representations] and (2) the [inferential mechanisms] they support.\n\nIn this paper we describe a [QA architecture] where questions are analyzed and candidate answers generated by 1) identifying [predicate argument structures] and [semantic frames] from the input and 2) performing [structured probabilistic inference] using the extracted relations in the context of a [domain and scenario model].\n\nA novel aspect of our system is a scalable and expressive representation of actions and events based on [Coordinated Probabilistic Relational Models (CPRM)].\n\nIn this paper we report on the ability of the implemented system to perform several forms of [probabilistic and temporal inferences] to extract answers to complex questions.\n\nOur [question answering system] takes [PropBank/FrameNet annotations] as input, uses the [PropBank targets] to indicate which actions are being described with which arguments, and produces an answer using [probabilistic models] of actions as the tools of inference.
365	558	Passage 1	No Difference	Passage 1	easier terms	both sound natural	simpler and shorter length	149	We show that using the SMT approach can find mistakes that common [proofreading tools] for native speakers often miss.	Our system was able to correct 61.81% of mistakes in a set of naturally-occurring examples of mass noun errors found on the World Wide Web, suggesting that efforts to collect [alignable corpora] of pre- and post-editing ESL writing samples offer can enable the development of SMT-based writing assistance tools capable of repairing many of the [complex syntactic and lexical problems] found in the writing of ESL learners.:::\n We utilize phrasal Statistical Machine Translation (SMT) techniques to correct ESL writing errors and demonstrate that this [data-intensive SMT approach] is very promising, but we also point out SMT approach relies on the availability of large amount of training data.
365	559	Passage 2	No Difference	Passage 2	easier terms and less technical vocabs	both sound natural	shorter and simpler sentences	150	We [utilize meta-patterns] of high-frequency words and content words in order to discover pattern candidates.:::\n Symmetric patterns are then identified using graph-based measures, and word categories are created based on [graph clique sets].	N/A
25	84	Passage 1	No Difference	Passage 1	easier to understand	both natural in English	simpler sentences	213	n/a	We show that [conventional context-free parsing techniques] can be used in creating a parse forest for a sentence in DOP1.
16	51	Passage 2	Passage 2	Passage 2	For people who has no idea what the topic is, passage 2 make it easier for readers to understand 	Simply because it is easier to understand 	Compared to passage 1 it is much easier to understand 	152	We propose, in the scenario of extracting is-a relations, one pattern-based approach and compared it with a baseline syntactic distributional similarity method (called syntactic co-occurrence in their paper).:::\n We propose a similar, highly scalable approach, based on an edit-distance technique, to learn lexico-POS patterns, showing both good performance and efficiency.	N/A
16	52	Passage 1	Passage 1	Passage 1	Concise and use simple words	Complexity in passage 2	Simpler vocabulary 	153	N/A	Abstracting from results for concrete test sets, we try to identify statistical and linguistic properties on that the performance of similarity metrics generally depends.
16	53	Passage 1	Passage 1	Passage 1	Clearer phrases0	Natural and easy to understand 	Easily understandable 	154	N/A	Unlike the basic connection structures (dependency structures) the parser gives, these can be used directly to understand meaning (semantic interpretation).
16	54	Passage 2	Passage 2	Passage 2	Easier words 	Natural	Easily understandable 	155	The system is tested on data from a specific competition in 2004 about identifying word roles and performs very well.	N/A
371	571	Passage 2	Passage 2	Passage 2	Passage2 는 Passage 1에 비해 jargon 이 거의 없고, 사용한 동사 (verb) 또한 쉬운 단어들로 구성되어 있음	Passage 2 의 문장에서는 문법 오류를 찾아볼 수가 없었음. 	Passage 2 는 장문이 비교적 없고, 문장을 구성하는 단어들 또한 쉬운 단어들로 구성되어 있어 전후 맥락을 파악하는데 용이했음	156	We use syntactic path patterns as features for supervised hyponymy and synonymy classifiers, [whose training examples are derived automatically from WordNet.]	N/A
371	572	Passage 1	Passage 1	Passage 1	쉬운 단어 구성	쉬운 단어 구성이 익숙한 문장 구조로 연결됨	문장을 뒷받침하는 부분이 적음	157	N/A	[Seeded with] a small number of transliteration pairs, our algorithm discovers multi-word NEs, and takes advantage of a dictionary (if one exists) to account for translated or partially translated NEs.
19	61	Passage 1	Passage 1	Passage 1	Easy	Simple	Easily understandable 	158	N/A	A Uniform Approach to Analogies Synonyms Antonyms and Associations Recognizing analogies (like comparisons), synonyms (words with similar meanings), antonyms (opposite words), and associations (related words) seem like four different jobs, needing different language processing methods.
19	62	Passage 1	Passage 1	Passage 1	Easier 	Simpler	Understandable 	159	N/A	Top Accuracy and Fast Dependency Parsing is not a Contradiction In addition to a high accuracy, short parsing and training times are the most important properties of a parser.
19	63	Passage 1	Passage 1	Passage 1	Easier	Simpler 	Understandable 	160	We propose a Tree-based Simplification Model (TSM), which, to our knowledge, is the first statistical simplification model covering splitting, dropping, reordering and substitution integrally.	N/A
19	64	Passage 2	Passage 2	Passage 2	Easier	Simpler 	Understandable 	161	Robust Sentiment Detection on Twitter from Biased and Noisy Data In this paper, we suggest a way to automatically find feelings in Twitter messages (tweets) by looking at how tweets are written and extra information about the words in these messages.	N/A
19	65	Passage 1	Passage 1	Passage 1	Easier 	Simple	Understandable 	162	N/A	By using 50 Twitter tags and 15 smileys (faces showing emotions) as labels for feelings, this method avoids the need for time-consuming manual labeling, allowing it to identify and classify different feeling types in short texts.
19	66	Passage 1	Passage 1	Passage 1	Easier	Simpler	Understandable 	163	N/A	D-PATR: A Development Environment For Unification-Based Grammars We describe systems in which FSs may be modified by default statements in such a way that this property does not automatically hold.
19	67	Passage 1	Passage 1	Passage 1	Easier	Simpler 	Understandable 	164	N/A	It will suggest that the methods and possibilities of CUGs make them worth further study in the larger field of research on unification grammars.
19	68	Passage 1	Passage 1	Passage 1	Easier 	Simpler 	Understandable 	165	The method relies on having large pairs of texts that are translations of each other.	N/A
19	69	Passage 2	Passage 2	Passage 2	Easy	Simple	Understandable 	166	Since the set of trees needed to parse an input sentence is supposed to be finite, the parser can use in principle any search strategy.	N/A
19	70	Passage 2	Passage 2	Passage 2	Easier 	Simpler 	Understandable 	167	In this paper, we explore a more daring idea: not only can one grammar be used by different processes working in different ways, but the same system for understanding and creating language can be used to handle the grammar in different modes.	N/A
371	573	No Difference	Passage 1	Passage 1	두 개의 구절 모두 문장을 구성할 때, 보편적인 단어로 동사를 사용하였음 	Passage 2에는 부자연스러운 문장이 약간 존재	문장의 길이 자체는 더 길지만, 문장 구조가 단순하여 이해하기 쉬웠음	168	N/A	Our research shows that this composite kernel can effectively capture both simple and complex features [without needing] a lot of extra work to create features.
371	574	Passage 1	No Difference	Passage 1	여러 번 읽어야 이해가 가능한 문장이 없었음	둘 다... 딱히 	문장이 짧지는 않지만, 주 내용을 뒷받침 해주는 것이 문장이 아닌 몇 개의 단어들로 구성되어 있다는 점이 이해 하기 쉬웠음 	169	We find that using a grammar structure that isn't broken into smaller parts scores an average of 72.3% accuracy on WSJ sentences with up to 40 words, while the broken-down version scores only 64.6% accuracy.	Unsupervised DOP models assign all possible binary trees to a set of sentences and next use (a large random subset of) all subtrees from these binary trees to compute the most probable parse trees.:::\n\n [To the best of our knowledge this] is the first paper which tests a maximum likelihood estimator for DOP on the Wall Street Journal, leading to the surprising result that an unsupervised parsing model beats a widely used supervised model (a treebank PCFG).
371	575	Passage 1	Passage 1	Passage 1	두 번째 문장에서 "how computational systems" 이 단어를 설명해주는 부분이 Passage 2에 비해 간결했음 	위와 같은 이유	Passage 2의 문장은 주어(S)와 동사(V) 사이의 뒷받침 하는 부분이 너무 김. 	170	N/A	In this paper, we show how computer systems that identify textual entailment, which is understanding if one piece of text logically follows from another, can improve the accuracy of current open-domain automatic question answering (Q/A) systems.:::\n In our tests, we demonstrate that using textual entailment information [to either sort or filter answers given by a Q/A system] can improve accuracy by up to 20% in total.
371	576	Passage 2	Passage 2	Passage 2	Passage 1에 비하면 어색한 부분이 없음 	구어체에서 쓰는 문장이 문어체에서 발견됨.	문장은 길지만, 구조가 익숙하므로 이해하기 쉬움.	171	Our tests on two real-world examples show this method works well compared to other systems and handles errors well.:::\n\n KRISP (Kernel-based Robust Interpretation for Semantic Parsing) (Kate and Mooney, 2006) is a system that learns [by example for understanding sentence meanings, using pairs of sentences and their meanings as learning material.]:::\n\n Our system learns [these tools for each rule] in the formal language structure.	N/A
371	577	No Difference	No Difference	No Difference	둘 다 쉬운 단어를 사용했고, 문장 구조 또한 충분히 예측 가능했음.	차이를 명시할 만큼의 문법적인 오류는 없었음	둘 다 문장이 길었지만, 연결어를 적절한 곳에 잘 활용하여 문장을 잘 나누어 주었기 때문에 이해하는 데 큰 문제는 없었음 	172	N/A	N/A
371	578	Passage 2	Passage 2	Passage 2	Passage 1에서는 일반적으로 쓰는 동사가 아닌 동의어를 억지로 끼워 넣는 표현이 종종 발견되었음.	Passage 1에서는 구어체 표현들이 종종 보였음	여러 번 읽을 필요가 없었음 	173	Empirical Lower Bounds On The Complexity Of Translational Equivalence This paper describes [a study of the patterns of how translations match up] between two languages, found in different sets of bilingual texts.:::\n\n These findings [help explain] why certain language rules haven't improved statistical translation methods, like phrase-based models that use limited state changes, and models that convert between different tree structures.	N/A
371	579	Passage 2	Passage 2	Passage 2	Passage 1 보다 쉬운 단어로 동사를 사용하였음.	위와 같은 이유	Passage 1 과는 달리 이전 모델 및 이론 등에 대해 부가적인 설명을 할 때, 어려운 표현 보다는 쉬운 표현을 썼음.	174	Our model makes use of a generalization of the commonly used Dirichlet distributions called Pitman-Yor processes which produce [power-law distributions more closely resembling those] in natural languages.	N/A
371	580	Passage 1	Passage 1	No Difference	Passage 2 보다 쉬운 단어 그리고 반복 사용	위와 같은 이유	문장 구조는 둘 다 단순하며 예측 가능했음. 	175	N/A	N/A
372	571	Passage 2	Passage 2	No Difference	Easy verb to read	More fluent sentence connection	No specific diff	176	Finally, we show that a taxonomy built using our algorithm shows a 23% relative F-score improvement over WordNet 2.1 on an independent testset of hypernym pairs.	We successfully add 10,000 new word groups to WordNet 2.1 with high accuracy, making 70% fewer mistakes compared to older methods.
375	581	No Difference	No Difference	Passage 1	no ambiguity	there is not much verb or noun difference	passage1 seems use more conjunction	177	We offer an alternative approach to resolve such irregularities by normalizing SMS texts before MT.	We offer a different solution to fix these differences by adjusting SMS texts before using MT.
375	582	Passage 2	No Difference	Passage 1	passage2 seems like deductive paper than passage 1	there is no big difference of grammatical error and fluency.	passage1 is more shorter sentence to read 	178	We show that a parser can be accurate and fast without needing large, manually-made treebanks from specific fields, making it easier to use in tools that need to understand sentence structures.	Evaluating The Accuracy Of An Unlexicalized Statistical Parser On The PARC DepBank We evaluate the accuracy of an unlexicalized statistical parser, trained on 4K treebanked sentences from balanced data and tested on the PARC DepBank.
21	61	Passage 2	Passage 1	Passage 2	easier words	natural with lack in details	much more understandable	179	N/A	M/A
21	62	Passage 1	Passage 1	Passage 2	clear descriptions for first-readers	easier to read	shorter than 1	180	N/A	We are convinced that the Hash Kernel and the parallelization can be applied successful to other NLP applications as well such as transition based dependency parsers, phrase structrue parsers, and machine translation.
21	63	Passage 2	Passage 2	Passage 2	no ambiguity	natural	easier words	181	N/A	N/A
21	64	Passage 1	Passage 2	Passage 1	easier words and phrases	natural	easy understanding	182	In our tests, we demonstrate that because our method captures a more general idea of tweets, it works better than older methods and handles imperfect and biased data better, which is the type of data from these sources.	In our experiments, we show that since our features are able to capture a more abstract representation of tweets, our solution is more effective than previous ones and also more robust regarding biased and noisy data, which is the kind of data provided by these sources.
21	65	Passage 2	Passage 2	Passage 1	easier words	natural	shorter	183	N/A	N/A
21	66	Passage 1	Passage 1	Passage 1	clear	natural	easily understandable	184	N/A	N/A
21	67	Passage 2	Passage 2	Passage 2	easier	natural	understandable	185	n/a	n/a
21	68	Passage 2	Passage 1	Passage 1	clear phrases	easy words used	shorter	186	n/a	The language model tells how probable a given sentence is in the source language, the translation model indicates how likely it is that a particular target sentence is a translation of a given source sentence, and the decoder is what actually takes a source sentence as input and produces its translation as output.
21	69	Passage 2	Passage 2	Passage 2	easier	easier and natural expressions	easy understanding	187	n/a	n/a
21	70	Passage 2	Passage 2	Passage 1	clear	natural	shorter	188	n/a	n/a
22	71	Passage 1	Passage 1	Passage 1	Shorter sentences.	Shorter sentences. Straight to the point.	Same reason	189	N/A	N/A
23	71	Passage 2	No Difference	Passage 2	Easier words	Both sounds natural in english	Simple, shorter sentences	190	The resulting system, Feature Structure based Tree Adjoining Grammars (FTAG), captures the principle of factoring dependencies and recursion, fundamental to TAG's.:::\n A Feature-based TAG consists of a set of (auxiliary or initial) elementary trees and of two tree-composition operations: substitution and adjunction.	N/A
23	72	Passage 1	No Difference	Passage 1	Easier words	Both sounds natural in English	shorter sentences	191	Our method combines two earlier, separate techniques for understanding word meanings: using digital dictionaries and spreading activation models [(a way to mimic how the brain processes information)].	We apply conventional spreading activation approaches to word sense disambiguation.:::\n Word Sense Disambiguation With Very Large Neural Networks Extracted From Machine Readable Dictionaries In this paper, we describe a means for automatically building very large neural networks (VLNNs) from definition texts in machine-readable dictionaries, and demonstrate the use of these networks for word sense [disambiguation.]:::\n Our method brings together two earlier, independent approaches to word sense [disambiguation]: the use of machine-readable dictionaries and spreading and activation models.
23	73	Passage 2	No Difference	Passage 2	Easy to understand	Both sounds natural	shorter sentences	192	The second central idea is to treat morphological disambiguation and syntactic labelling by the same mechanism of discarding improper alternatives.:::\n We see this task as one of inferring surface structure from [a stream of concrete tokens] in a basically bottom-up mode.:::\n The ensemble of constraints for language L [constitute] a Constraint Grammar (CG) for L.:::\n One central idea is to maximize the use of morphological information for parsing purposes.:::\n Our input tokens to CGP are [morphologically analyzed word-forms.]	N/A
23	74	Passage 1	No Difference	Passage 1	Easier words	Both sounds natural	Simple, shorter sentences	193	N/A	N/A
23	75	Passage 2	No Difference	Passage 2	Easier words	Both sounds natural	shorter words	194	A synchronous derivation process for the two syntactic structures of both languages suggests the level of cross-lingual isomorphism between the two trees (e.g.:::\n The formalism's intended usage is to relate expressions of natural languages [to their associated semantics represented in a logical form language], or to their translates in another natural language; in summary, we intend it to allow TAGs to be used beyond their role in syntax proper.	N/A
23	76	No Difference	No Difference	No Difference	Both easy to undersatnd	Both sound natural	Both are simple	195	The type system supports an object-oriented method (a way of organizing information like objects) for describing language by providing a way to share properties [(multiple inheritance)] and a way to define relations between different language levels, treated as classes of objects.	na
23	77	No Difference	No Difference	No Difference	Both easy to understand	Both sound natural	No difference	196	This paper presents an automatic scheme for collecting statistics on cooccurrence patterns in a large corpus.	na
23	78	Passage 1	No Difference	No Difference	easy to understand	both sound natural	both are simple	197	na	The difficulties of identifying words include (l) the identification of complex words, such as Determinative-Measure, reduplications, derived words etc., (2) the identification of proper names,(3) resolving the [ambiguous segmentations.]:::\n We adopt a matching algorithm with 6 different [heuristic rules] to resolve the ambiguities and achieve a 99.77% of the success rate.
23	79	No Difference	No Difference	No Difference	no difference	no difference	no difference	198	n/a	n/a
23	80	Passage 1	No Difference	Passage 1	easier words	Both sound natural	simpler sentences	199	n/a	We apply generalizations about the salience of properties of objects and conventions about what words make base level attributions to incrementally select words for inclusion in a description.
376	581	No Difference	No Difference	No Difference	no difference	both sound natural	no difference	200	n/a	n/a
376	582	Passage 1	No Difference	Passage 1	easier to understand	both sound natural	simpler sentences	201	n/a	We demonstrate that a parser which is competitive in accuracy (without sacrificing processing speed) can be quickly tuned without reliance on large [in-domain manually-constructed treebanks.]:::\n We show that the system has equivalent accuracy to the PARC XLE parser when the [morphosyntactic features] in the original DepBank gold standard are taken into account.
376	583	Passage 2	No Difference	Passage 2	provides extra explanation	both sound natural	simpler sentences	202	We use a publicly available structured output SVM to create a [max-margin syntactic aligner ]with [a soft cohesion constraint].	This aligner is the first, as far as we know, to use a learning method that focuses on differences to train an ITG bitext parser (a tool for analyzing bilingual text).:::\n We use dependency structures as flexible rules to improve word pairings in an ITG framework (a method for managing translations).
376	584	Passage 1	No Difference	Passage 1	easier	both sound natural	shorter sentences	203	n/a	In dependency-based parsing, several constraints have been proposed that restrict the class of permissible structures, such as [projectivity, planarity, multi-planarity, well-nestedness, gap degree, and edge degree].:::\n [In this paper, we review and compare the different constraints theoretically, and provide an experimental evaluation using data from two treebanks, investigating how large a proportion of the structures found in the treebanks are permitted under different constraints.]
376	585	Passage 2	No Difference	No Difference	easy to understand	both sound natural	shorter, simpler	204	Given a user's query, the system will automatically create patterns to extract [salient relations] in the text of the topic, and build tables from the extracted information using paraphrase discovery technology.	n/a
376	586	Passage 1	No Difference	Passage 1	shorter, easier	both sound natural	easier	205	n/a	Since the error surface for many natural language problems is piecewise constant and riddled with local minima, many systems instead optimize log-likelihood, which is conveniently differentiable and convex.
376	587	Passage 2	No Difference	No Difference	easier words	both sound natural	both are simple	206	We [conceptualize] a network of words that capture [the word co-occurrence patterns].	n/a
376	588	Passage 1	No Difference	Passage 1	easier	both natural	shorter, simpler	207	n/a	The new version includes a revised and more [semantically-motivated output representation], an enhanced grammar and [part-of-speech tagger lexicon], and a more flexible and semi-supervised training method for the structural parse ranking model.
376	589	Passage 2	No Difference	Passage 2	easier to understand	both sound natural	simpler, shorter	208	We propose a novel model for unsupervised word alignment which explicitly takes into account [target language constituent structure], while [retaining the robustness and efficiency of the HMM alignment model].:::\n Tailoring Word Alignments to Syntactic Machine Translation Extracting tree transducer rules for syntactic MT systems can be hindered by word alignment errors that [violate syntactic correspondences].	n/a
376	590	No Difference	No Difference	No Difference	both were easy to understand	both sound natural in English	both are simple	209	n/a	n/a
25	81	Passage 2	No Difference	Passage 2	extra explanation	both sound natural	simpler sentences	210	Finally, we should how SLTAG enables to define a [lexicalized version of stochastic context-free grammars ]and we report [preliminary experiments] showing some of the advantages of SLTAG over stochastic context-free grammars.	n/a
25	82	Passage 1	No Difference	Passage 1	easy to understand	both natural	simpler sentences	211	n/a	The categories listed for a word in Roger's index tend to correspond to sense distinctions; thus selecting the most likely category provides a useful level of sense disambiguation.:::\n Applied to the 10 million word Grolier's Encyclopedia, the system [correctly disambiguated] 92% of the instances of 12 [polysemous words] that have been previously studied in the literature.:::\n From [the perspective of a generative process], neighboring words of a target are generated by the target's underlying sense.
25	85	Passage 1	No Difference	Passage 2	extra explanation	both natural	simpler, shorter sentences	214	We present a surface-syntactic analyser that extracts maximal length noun phrases mainly sequences of determiners, [premodifiers, nominal heads,] and certain kinds of post modifying prepositional phrases and adjectives from French texts for terminology applications.:::\n In the first stage, LEXTER uses a base of rules designed to identify [frontier markers] in view to analysing the texts and extracting maximal-length noun phrases.	n/a
25	86	No Difference	No Difference	No Difference	no difference	no difference	no difference	215	In this paper, a new part-of-speech tagging method using neural networks (Net-Tagger) is introduced and its performance is compared to that of an HMM-tagger (a previous method from Cutting et al., 1992) and a trigram-based tagger (another method from Kempe, 1993).	n/a
25	87	Passage 2	No Difference	Passage 2	easier to understand	both sound natural	simpler	216	The proposed Japanese [morphological analyzer] achieved 95.l% recall and 94.6% precision for open text when it was trained and tested on the ATR Corpus.	n/a
25	88	No Difference	No Difference	Passage 1	both are easy to understand	both sound natural	simpler sentence structure	217	n/a	Comlex Syntax: Building A Computational Lexicon We describe the design of Complex Syntax, a computational lexicon providing detailed syntactic information for approximately 38,000 English headwords.
25	89	Passage 2	No Difference	No Difference	easy to understand	both sound natural	both are simple	218	n/a	n/a
25	90	Passage 1	No Difference	Passage 1	easier to understand	both sound natural	simpler sentences	219	n/a	[Discriminant analysis makes it possible to use a large number of parameters taht may be specific for a certain corpus or information streatm, and combine them into a small number of function, with the parameters weighted on bais of how useful they are for discriminating text genres.]:::\n We word length [as an indicator of formality] for applications such as genre classification.
\.


--
-- Name: responses_id_seq; Type: SEQUENCE SET; Schema: public; Owner: postgres
--

SELECT pg_catalog.setval('public.responses_id_seq', 219, true);


--
-- Name: responses responses_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.responses
    ADD CONSTRAINT responses_pkey PRIMARY KEY (id);


--
-- PostgreSQL database dump complete
--

